{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 项目说明\n",
    "\n",
    "光学不练，假把式；光练不写，傻把式。计算机二进制加法，从低位加到高位，高位的结果受低位运算结果的影响。也就是说，需要有“记忆”，记住前面的运算结果。因此，RNN 应该适合“学习”二进制的加法。\n",
    "\n",
    "### 软件版本\n",
    "\n",
    "* Python 3.5\n",
    "* TensorFlow 1.4\n",
    "\n",
    "### 数据集说明\n",
    "\n",
    "随机产生两个整数 a 和 b，计算它们的和 c。这两个整数的二进制序列 A_0 和 B_0 作为输入数据，和的二进制序列作为输出标签 C_0。根据这个方法，随机生成若干数据，分成训练数据和测试数据。\n",
    "\n",
    "二进制的序列做加法时，是从右往左进行加法；而序列的正常顺序是从左往右。因此，在 RNN “学习”之前，需要对二进制序列进行左右翻转。这里使用 `np.flip(arr, axis=None)` 函数进行操作。\n",
    "\n",
    "#### 数据维度说明\n",
    "\n",
    "RNN 单次运算，输入数据为 [a[i], b[i]]， 输出数据为 d[i]，本案例中的二进制序列为 8 位。使用 TensorFlow 时，输入张量为 [batch_size, 8, 2]，输出张量为  [batch_size, 8]。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## TensorFlow RNN 的正确打开方式\n",
    "\n",
    "参看 [TensorFlow中RNN实现的正确打开方式](https://zhuanlan.zhihu.com/p/28196873)，采用 TensorFlow 封装好的 RNN 模块时，使用起来基本可以是这个套路。\n",
    "\n",
    "TensorFlow debug 是很困难的，经过一天的各种报错折磨，终于跑通了代码。这里进行一些经验总结。\n",
    "\n",
    "* 使用 RNN 模块时，需要指定 RNN cell 的记忆单元的数量。而记忆单元的数量，需要和输入数据张量的表示数量的第一维度相等。一般用 batch_size 表示这个维度，这就意味着，这里定义的计算图的输入张量的维度时固定的，必须是一个一个的 batch_size 的数据喂进去。这就使得学习过程变得很呆板了。（应该有解决办法，TODO）\n",
    "* TensorFlow 进行运算时，对数据类型有要求。很多运算函数，要求输入变量是相同的类型。这个时候，可以使用 `tf.cast()` 来强行转换类型，如 `X = tf.cast(X, tf.float32)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from tensorflow.contrib import rnn as rnn_cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 生成数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gen_binary_seq(binary_dim):\n",
    "    int2binary = {}\n",
    "    max_number = pow(2, binary_dim)\n",
    "    int_list = range(max_number)\n",
    "    binary = np.unpackbits(\n",
    "        np.array([int_list], dtype=np.uint8).T, axis=1)\n",
    "    for i in int_list:\n",
    "        int2binary[i] = binary[i]\n",
    "    return int_list, int2binary\n",
    "\n",
    "def binary2int(binary_seq):\n",
    "    value = 0\n",
    "    for i, bit in enumerate(reversed(binary_seq)):\n",
    "        value += bit * np.power(2, i)\n",
    "    return value\n",
    "\n",
    "def gen_data(n_samples, int_list, int2binary, seed=None):\n",
    "    X, y = [], []\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "    for i in range(n_samples):\n",
    "        a = np.random.choice(int_list[:len(int_list)//2])\n",
    "        b = np.random.choice(int_list[:len(int_list)//2])\n",
    "        c = a + b\n",
    "        X.append([int2binary[a], int2binary[b]])\n",
    "        y.append(int2binary[c])\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def shuffle_data(X, y, seed=None):\n",
    "    \"\"\" Random shuffle of the samples in X and y \"\"\"\n",
    "    idx = np.arange(X.shape[0])\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "    np.random.shuffle(idx)\n",
    "    return X[idx], y[idx]\n",
    "\n",
    "\n",
    "def train_test_split(X, y, test_size=0.5, shuffle=True, seed=None):\n",
    "    \"\"\" Split the data into train and test sets \"\"\"\n",
    "    if shuffle:\n",
    "        X, y = shuffle_data(X, y, seed)\n",
    "    split_id = int(math.ceil(X.shape[0] * (1 - test_size)))\n",
    "    X_train, X_test = X[:split_id], X[split_id:]\n",
    "    y_train, y_test = y[:split_id], y[split_id:]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "binary_dim = 8\n",
    "int_list, int2binary = gen_binary_seq(binary_dim)\n",
    "n_samples = 1000\n",
    "seed = 0\n",
    "X, y = gen_data(n_samples, int_list, int2binary, seed)\n",
    "X = np.flip(X, axis=-1)  # flip\n",
    "y = np.flip(y, axis=-1)\n",
    "X = X.transpose((0, 2, 1))  # [n, 2, 8] ==> [n, 8, 2]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 定义超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class HParam(object):\n",
    "    batch_size = 64\n",
    "    seq_length = 8\n",
    "    num_layers = 2\n",
    "    state_size = 16\n",
    "    learning_rate = 0.01\n",
    "args = HParam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 定义 RNN 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class RNN(object):\n",
    "    def __init__(self, sess, args, seed=None):\n",
    "        # initialize neural network weights\n",
    "        if seed:\n",
    "            tf.random.seed(seed)\n",
    "        self.batch_size = args.batch_size\n",
    "        self.seq_length = args.seq_length\n",
    "        self.num_layers = args.num_layers\n",
    "        self.state_size = args.state_size\n",
    "        self.learning_rate = args.learning_rate\n",
    "        self.sess = sess\n",
    "\n",
    "        with tf.name_scope('inputs'):\n",
    "            self.X = tf.placeholder(tf.float32, [self.batch_size, self.seq_length, 2])\n",
    "            self.y = tf.placeholder(tf.float32, [self.batch_size, self.seq_length])\n",
    "\n",
    "        with tf.name_scope('model'):\n",
    "            self.cell = rnn_cell.BasicRNNCell(num_units=self.state_size)\n",
    "            def _get_cell(state_size):\n",
    "                return rnn_cell.BasicRNNCell(num_units=state_size)\n",
    "            self.cell = rnn_cell.MultiRNNCell([_get_cell(self.state_size) for _ in range(self.num_layers)])\n",
    "            self.initial_state = self.cell.zero_state(\n",
    "                self.batch_size, tf.float32)\n",
    "            outputs, last_state = tf.nn.dynamic_rnn(\n",
    "                self.cell, self.X, initial_state=self.initial_state)\n",
    "\n",
    "        with tf.name_scope('loss'):\n",
    "            weights = tf.Variable(tf.truncated_normal([self.state_size, 1], stddev=0.01))\n",
    "            bias = tf.zeros([1])\n",
    "            outputs = tf.reshape(outputs, [-1, self.state_size])\n",
    "            logits = tf.sigmoid(tf.matmul(outputs, weights) + bias)\n",
    "            self.predictions = tf.reshape(logits, [-1, binary_dim])\n",
    "            self.y_pred = tf.round(self.predictions)\n",
    "            self.cost = tf.losses.mean_squared_error(self.y, self.predictions)\n",
    "            # targets = tf.reshape(self.y, [-1])\n",
    "            tf.summary.scalar('loss', self.cost)\n",
    "\n",
    "        with tf.name_scope('accuracy'):\n",
    "            correct_prediction = tf.equal(tf.cast(tf.reduce_sum(self.y_pred, axis=1), tf.float32),\n",
    "                                          tf.cast(tf.reduce_sum(self.y, axis=1), tf.float32))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "        with tf.name_scope('optimizer'):\n",
    "            self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.cost)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.sess.run(self.y_pred, feed_dict={self.X: x})\n",
    "\n",
    "    def fit(self, X_train, y_train, n_epochs=10, display_epoch=10):\n",
    "\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        for i in range(1, n_epochs+1):\n",
    "            X_train, y_train = shuffle_data(X_train, y_train)\n",
    "            for j in range(0, X_train.shape[0], self.batch_size)[:-1]:\n",
    "                x = X_train[j: j + self.batch_size]\n",
    "                y = y_train[j: j + self.batch_size]\n",
    "                loss, acc, _ = self.sess.run([self.cost, self.accuracy, self.optimizer],\n",
    "                                             feed_dict={self.X: x, self.y: y})\n",
    "            if i % display_epoch == 0:\n",
    "                print('eproch {:<3}, training score: {}'.format(i, self.get_accuracy(X_train, y_train)))\n",
    "        print('-------------------------------')\n",
    "        print('Training Finished!')\n",
    "\n",
    "    def get_accuracy(self, X_test, y_test):\n",
    "        Acc = []\n",
    "        for j in range(0, X_test.shape[0], self.batch_size)[:-1]:\n",
    "            x = X_test[j: j + self.batch_size]\n",
    "            y = y_test[j: j + self.batch_size]\n",
    "            acc = self.sess.run(self.accuracy, feed_dict={self.X: x, self.y: y})\n",
    "            Acc.append(acc)\n",
    "        return sess.run(tf.reduce_mean(Acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eproch 2  , training score: 0.16875000298023224\n",
      "eproch 4  , training score: 0.15937499701976776\n",
      "eproch 6  , training score: 0.18125000596046448\n",
      "eproch 8  , training score: 0.996874988079071\n",
      "eproch 10 , training score: 1.0\n",
      "eproch 12 , training score: 1.0\n",
      "eproch 14 , training score: 1.0\n",
      "eproch 16 , training score: 1.0\n",
      "eproch 18 , training score: 1.0\n",
      "eproch 20 , training score: 1.0\n",
      "-------------------------------\n",
      "Training Finished!\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "clf = RNN(sess=sess, args=args, seed=seed)\n",
    "clf.fit(X_train, y_train, n_epochs=20, display_epoch=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuray: 100 %\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest accuray: {:.4g} %'.format(clf.get_accuracy(X_test, y_test) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "### 验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True binary: [1 0 1 0 0 0 0 0]\n",
      "Pred binary: [1 0 1 0 0 0 0 0]\n",
      "guess 86 + 74 ==> 160, right answer == 160\n",
      "-------------------------------\n",
      "True binary: [0 1 0 0 1 1 0 1]\n",
      "Pred binary: [0 1 0 0 1 1 0 1]\n",
      "guess 12 + 65 ==> 77, right answer == 77\n",
      "-------------------------------\n",
      "True binary: [1 1 1 1 0 0 0 0]\n",
      "Pred binary: [1 1 1 1 0 0 0 0]\n",
      "guess 117 + 123 ==> 240, right answer == 240\n",
      "-------------------------------\n",
      "True binary: [1 0 0 1 0 1 1 1]\n",
      "Pred binary: [1 0 0 1 0 1 1 1]\n",
      "guess 28 + 123 ==> 151, right answer == 151\n",
      "-------------------------------\n",
      "True binary: [0 1 1 0 1 0 1 0]\n",
      "Pred binary: [0 1 1 0 1 0 1 0]\n",
      "guess 30 + 76 ==> 106, right answer == 106\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test[0: clf.batch_size])\n",
    "y_pred = sess.run(clf.y_pred, feed_dict={clf.X: X_test[0: clf.batch_size]})\n",
    "for i in range(5):\n",
    "    x_1_binary = np.flip(X_test[i][:, 0], axis=0)\n",
    "    x_2_binary = np.flip(X_test[i][:, 1], axis=0)\n",
    "    y_sample_binary = np.flip(y_test[i], axis=0)\n",
    "    y_pred_binary = np.flip(y_pred[i], axis=0).astype(np.int32)\n",
    "    print('True binary:', str(y_sample_binary))\n",
    "    print('Pred binary:', str(y_pred_binary))\n",
    "    a, b, c, d = map(binary2int, [x_1_binary, x_2_binary, y_pred_binary, y_sample_binary])\n",
    "    print('guess {} + {} ==> {}, right answer == {}'.format(a, b, c, d))\n",
    "    print('-------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
